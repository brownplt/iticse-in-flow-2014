# Are there things your assignments could do better based on reading this?

I like the use of multiple representations of the same artifact (in
this case, code).  I like this more active version of the usual
clicker approach.  This makes me think about how to use
peer-contributions more as a component of in-class discussions in a
scalable way.

# Are there things this assignment could do better based on your assignments?

This comment doesn't arise from my assignment, but just something I
thought of.  CFGs are easier to compare algorithmically than code.  In
theory, it would seem possible to guarantee that each student will
have to review a CFG that differs structurally from his own.  That
might make the process more thought-provoking.

# Any other comments on course structure?

I do think of this as in-flow: to me, in-flow means that students are
getting feedback while they are in the active process of working
through a problem or concept (rather than after all work on a problem
has been submitted).

# Looking ahead to including these in a report, any writing comments?

Not on the writing of this, but the idea of in-flow review as an
in-lecture tool seems worth covering outside of this specific case
study.  

It could also be interesting to think about what this exercise could
look like if not constrained by Informa's capabilities.  For example,
what's a meaningful non-boolean rubric for the time constraints of
in-lecture peer review?
