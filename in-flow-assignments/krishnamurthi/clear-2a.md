# Are there things your assignments could do better based on reading this?
I like the rubric to aid design critiques, and the complementary use of the overly simplistic staff submission to enforce greater rigor in initial student submissions
# Are there things this assignment could do better based on your assignments?
I wondered if there was a design flaw in the enforced anonymity of peers and the potential leakage of information.  Would a continuous review model by pairing students be a more positive approach? Is there aany whole class discussion of intermediate solutions so the pros and cons could maybe be discussed in a wider forum?  
# Any other comments on course structure?
I think it is a nice assignment.  Do the students have to adopt any modelling formalism preparatory to or in addition to the formal language specification for the verification tool? 
# Looking ahead to including these in a report, any writing comments?
Do any model checkers have a more evolved teaching context design to overcome the single file problem?  is that worth expanding upon by comparing relative merits of different tools? The paper below by Moti Ben Ari may be relevant here:
Mordechai (Moti) Ben-Ari. 2010. A primer on model checking. ACM Inroads 1, 1 (March 2010), 40-47. DOI=10.1145/1721933.1721950 http://doi.acm.org.ezproxy.aut.ac.nz/10.1145/1721933.1721950 
