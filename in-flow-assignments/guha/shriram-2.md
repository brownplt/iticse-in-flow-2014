# Are there things your assignments could do better based on reading this?

Not clear. Seems similar to things we do.

# Are there things this assignment could do better based on your assignments?

I wonder about the use of code review for this. It seems rather difficult to do -- I know I would have trouble reading a parser's implementation (even with parser combinators) and inferring its behavior. This seems like a place where "fuzz testing" (where the students are the fuzzers) could be far more effective. Of course students can always run and try to confound the parser, but the prompt is stated in a way that suggest static reading. A better thing might be to expressly make the peer-review process try to break the other person's parser -- with the attendant benefit that in so doing, the reviewer will also realize possible weaknesses with their own parser. (This is a little bit like in-flow TestFest.)

# Any other comments on course structure?

No, this looks good.

# Looking ahead to including these in a report, any writing comments?

N/A
