The large number of reviews produced in IFPR, 
especially in large classes, 
can make it challenging for an instructor to monitor students' progress and to support their learning. 
Instructors benefit from knowing whether there are students who consistently write weak/strong reviews, 
superficial or sloppy reviews, 
or misleading or overly generous reviews. 
They also benefit from realizing misconceptions that reoccur across many reviewers, 
which may be rectified with further explanations in class.

To achieve these goals, 
instructors can benefit from organizing submissions or reviews in various ways. 
One such way is to allow instructors to associate arbitrary tags with each submission or review, 
such as "sloppy" or "discuss in class", "ignore", "insufficient test coverage", or "misunderstood requirement B". 
Instructors can then search or group submissions or reviews by tags, 
or use tags as categories when producing analytical visualizations. 
Tags can be visible only to instructors, or instructors can make tags visible to authors or reviewers. 
Another way to organize submissions or reviews is to cluster them automatically by various criteria, 
similar to Expertiza's automatic meta-reviewing categories [Expertiza]. 
Example criteria include the length of the reviews or their tone ("positive", "neutral", or "negative"), 
which may be detectable automatically using natural language processing techniques. 
Based on this automatic and manual organization, 
instructors can identify recurring misconceptions, 
or they can select representative exemplars of reviews to be presented in class. 
Finally, the information in reviews (e.g., feedback in each rubric, or scores on Likert scales) 
can be used to organize submissions, 
and information in meta-reviews can be used to organize reviews.

Instructors as well as students also can benefit from analytic visualizations or dashboards. 
Visualizations presenting activity over time can help to understand the timeliness of reviews 
or a student's progress over time in terms of the quality of their submissions or their reviews. 
Visualizations of reviewer-author relationships, 
which can include various historic aspects, 
such as the quality of their past submissions or the usefulness of their past reviews, 
can help with reviewer assignment.  
Visualizations superimposing reviews on top of submissions or meta-reviews on top of reviews 
can provide a compact picture of a certain artifact to authors, reviewers, or instructors.
