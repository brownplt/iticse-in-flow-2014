Any use of peer-review must choose whether to include any grading or
feedback on the review contents.  We use the term _meta-review_ to
refer to any feedback on a review (because feedback can be considered
a review of a review).  Feedback can take many forms: the author who
received a review could report on whether the review was constructive
or led to changes, course staff could formally grade reviews and
return comments to the reviewer, or third parties could comment on the
relative merits across a set of reviews.  Which model makes sense
depends on factors including the learning objectives for IFPR,
features of peer-review software, and course logitics (such as staff
size relative to student population).

Much of the group's discussion around meta-reviewing applies to
peer-review in general, rather than only IFPR.  The IFPR context is
mostly relevant when considering whether reviews are sufficiently
actionable to let students benefit from reviews to improve their own
work.  We describe both general design decisions around meta-reviews
and those particular to IFPR in this section.

According to Ramachandran and Gehringer[cite](rg:auto-assess-rev-lsa) reviews consist of 
(1) summative, (2) problem detection, and (3) advisory content.
Meta-reviews can report on each of these three types of contents, each
of which is valuable in its own way.
While summative contents can reflect a reviewer's understanding, 
problem detection content directly helps a student to identify opportunities for improvement, 
and advisory content points out ways in which students might improve. 
Meta-reviews can include information on which parts of a review were
constructive, and which led to actual changes.  Meta-reviews written
by authors of submissions can also include rebuttals to aspects of a
review: in IFPR, such rebuttals can arise when students are debating
the requirements of an exercise through the review process (a healthy
outcome relative to the goals of IFPR).


While one generally may prefer to eliminate low quality contents in reviews, 
in a pedagogical context also receiving some low quality review contents can be beneficial. 
While in traditional educational settings students may trust all the feedback they receive from the instructor, 
in IFPR students have to learn to assess the value of the reviews they receive. 
They will have to learn to triage review comments into those they will act upon and those they will ignore. 
Moreover, having a diversity of reviews, 
maybe even contradicting reviews, 
can be a starting point for valuable discussions in class.

This kind of information can help to train reviewers to not submit "brain dumps" 
of everything that might possibly be wrong, 
but to provide valuable but concise reviews. 

Instructors may seek to use meta-reviews to monitor the IFPR process.
Given the quicker turn-around times inherent to IFPR, such monitoring
benefits from tool support and structural elements of meta-reviews.
For example, asking students to rate the reviews they receive on a
simple Likert scale makes it easy for an instructor to focus on
potentially problematic reviews without undue burden on the students.
In some IFPR configurations, software tools that include automatic
grading could report partial information on whether student
performance improves following the review phase.  Such information
would be most useful for identifying cases in which poor work did not
improve, prompting the instructor to check on whether the author had
received useful and actionable advice through reviews.

Meta-reviewing incurs a cost. 
Whether or not meta-reviews are worth that cost depends on the learning goals: 
if teaching how to review is important, meta-reviews are essential; 
however if the learning goals focus on artifact production or performance, 
and if the reviewers are experienced, 
meta-reviews may be less essential. 
An alternative to providing meta-reviews for each review is to provide a few example reviews and their meta-reviews. 
To not tempt students to simply reuse the best example review comments, 
these exemplar reviews can come from an assignment that is different from the current assignment.

Besides providing informative meta-reviews, 
[educators believing in the value of extrinsic motivation :-) ] might also wish to grade reviews. 
Such grades for reviews might simply be based on whether or not a review was submitted, 
or whether a review was submitted in a timely manner, 
or they may be based on any of the criteria mentioned above. 
Similarly, meta-reviews could be graded, too.

